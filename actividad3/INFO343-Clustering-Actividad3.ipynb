{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1 align=\"center\">Explorar el concepto de Pluralismo utilizando la Ciencia de los Datos: un estudio de caso con el ecosistema mediático de Chile</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div align=\"center\"><i>Autores: Profesores y Estudiantes del Magíster en Informática (Universidad Austral de Chile)</i></div>\n",
    "<div align=\"center\"><i>I semestre 2018</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Objetivo de investigación general</h2>\n",
    "<ul>\n",
    "<li><p>El <b>Pluralismo</b> de los medios es un principio que garantiza que l@s ciudadan@s disponen de una información pólitica e ideólogica diversificada, permitiendoles ejercer su <i>espiritu crítico</i> y su <i>libertad de pensar</i>. Por lo tanto, la Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO) definió el pluralismo de los medios como una condición necesaria para construir la Democracía.</p></li>\n",
    "<li><b>Medir para entender</b>: <i>“When you can measure what you are speaking about, and express it in numbers, you know something about it; but when you cannot measure it, when you cannot express it in numbers, your knowledge is of a meagre and unsatisfactory kind; it may be the beginning of knowledge, but you have scarcely, in your thoughts, advanced to the stage of science, whatever the matter may be.”</i> - Lord Kelvin (1883)\n",
    "<li><b>Pregunta general:</b> ¿La Informática, más particularmente la Ciencia de los Datos, puede medir el Pluralismo de los medios? ¿Se puede establecer un protocolo computacional para medir y entender varias facetas del Pluralismo de los Medios basandose sobre técnicas de Clustering de datos?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Experimentación de Ciencia de los Datos</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>1. Definir una pregunta de investigación </b></h3>\n",
    "\n",
    "<p><u>Ejemplos de preguntas:</u></p>\n",
    "<ul>\n",
    "<li>En el marco de una temática (<i>Mapuche, Cambio climático, Feminismo, Sexismo, etc.</i>), ¿en cuántos tópicos se dividen los discursos de los medios de prensa? ¿Existen diferencias significativas entre los distintos medios? </li>\n",
    "<li>En el marco de una semana de noticias, ¿en cuántos tópicos se dividen las noticias? ¿Existen diferencias significativas entre los distintos medios?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Recopilar y preparar los datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1493"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Cargar el dataset de tweets\n",
    "df_feminismo = pd.read_csv('datasets/sophia_mapuche_v2.csv',delimiter=\"|\", header=None)\n",
    "df_feminismo\n",
    "\n",
    "#selección de los mensajes\n",
    "docs = df_feminismo[3].as_matrix()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/roberto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/roberto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Explorar los datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10241.54412489984\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: newsletter tu correos emol farox guioteca entérate contáctenos quieres hoyxhoy.cl anunciar elige ¿cuándo soychile.cl recibirás inmobiliaria pronto sucede propiedades autolocal.cl suscríbete sa futuro condiciones valor recibir términos periodística sociedad publicado\n",
      "Topic #1: carabineros comuneros pueblos huelga ley conflicto territorio hambre nos cultura comuna nacional hasta violencia hay pero lugar nuestra años caso tiene días tras dos fueron presos año e indígenas zona\n",
      "Topic #2: cultura pueblos muy encuentro universidad historia pero nacional alejandro salud huilliche militares hay acuerdos sino tiene guillier cultural dijo poesía machi taller social según obra uno senador violeta dio parciales\n",
      "Topic #3: lleu koz nuevo tu wiñoy valor tripantu encuentro loading estación poesía junio newsletter parlamento condición raíces hemisferio año frente tags correo invierno los/as organizado día tendrán acuerdos autoridades recuperación daniela\n",
      "Topic #4: audio escuchar https video yo organizaciones beausejour lanzaron suprema winkul público nacido deporte jugador lupa piedra cultura versión último ver lengua próximo duramente argumentó werken.cl señaló septiembre junta principales chilevision\n",
      "Topic #5: loading working playlists neira marivil enseñaron orgulloso koz neruda padres desayuno panguipulli alumno mis ingeniería o´higgins universitaria sexta estoy vestimenta huerta bernardo convoca gloria lenguaje moneda protected orgullosa ruca típica\n",
      "Topic #6: proyecto pueblos educación lengua originarios asociación política violencia cultura corfo apoyo opinion amcam desarrollo mujeres conflicto saavedra comuna emprendimiento intercultural argentina llaitul martes enama reyes chilevisión kast ley cam indígenas\n",
      "Topic #7: indígenas pueblos bachelet año bandera presidenta pitrufquén alcalde originarios huala museo ellos nacional luis comuna jaramillo reconocimiento junto cultura muestra frente e gastronomía argentina diversidad ruka plan medios quiero causas\n",
      "Topic #8: tweet información instantáneamente tu tus twitter te web cualquier pulsa actualizaciones copiando ubicación añade código desarrolladores problema siguiente tema tweets momento icono haz nuevo saturado tendrás ¿intentar inténtalo únete enviarlo\n",
      "Topic #9: dos dejaron sujetos fundo tu curacautín ciento máquina lugar ceremonial sector trabajadores newsletter produjo febrero collipulli manuel alusivos teléfono destruido recibirás hija conocida comuna protected sociedad email cultura conflicto jornada\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aplicando Modelos Probabilistas de Tópicos y LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.2, min_df=7,\n",
    "                                stop_words='english',tokenizer=tokenize_only, ngram_range=(1,1))\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "diccionario= tf_vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "#Estimación de LDA con Bayes Variacional\n",
    "lda = LatentDirichletAllocation(n_components=10, max_iter=10,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "#Cálculo de índice de ajuste de los datos\n",
    "print(lda.perplexity(tf))\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "print_top_words(lda, diccionario, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
